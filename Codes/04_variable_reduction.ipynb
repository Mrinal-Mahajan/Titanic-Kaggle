{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew,kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../pickles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical=pickle.load(open('numerical.pickle','rb'))\n",
    "categorical = pickle.load(open('categorical.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../output_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_v03.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index('PassengerId',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edd(data):\n",
    "    df_desc = data.describe().transpose()\n",
    "    df_desc['Var'] = df_desc.index\n",
    "    df_desc.reset_index(inplace=True)\n",
    "    df_desc.drop('count',axis=1,inplace=True)\n",
    "    df_desc['skewness'] = df_desc['Var'].apply(lambda x: skew(np.array(data.loc[data[x].notnull(),x])))\n",
    "    df_desc['kurtosis'] = df_desc['Var'].apply(lambda x: kurtosis(np.array(data.loc[data[x].notnull(),x]),fisher=False))\n",
    "    df_desc['99%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.99))\n",
    "    df_desc['95%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.95))\n",
    "    df_desc['90%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.90))\n",
    "    df_desc['10%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.1))\n",
    "    df_desc['5%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.05))\n",
    "    df_desc['1%'] = df_desc['Var'].apply(lambda x: data[x].quantile(.01))\n",
    "    df_desc['mean-3sigma'] = df_desc['mean'] - 3*df_desc['std']\n",
    "    df_desc['mean+3sigma'] = df_desc['mean'] + 3*df_desc['std']\n",
    "    df_desc['mean-2sigma'] = df_desc['mean'] - 2*df_desc['std']\n",
    "    df_desc['mean+2sigma'] = df_desc['mean'] + 2*df_desc['std']\n",
    "    df_desc['type']='numeric'\n",
    "    \n",
    "    def is_category(col):\n",
    "        return 'float' not in str(data[col].dtype) and 'int' not in str(data[col].dtype)\n",
    "    \n",
    "    categorical = [col for col in data.columns if is_category(col)]\n",
    "    df_categorical = pd.DataFrame()\n",
    "    df_categorical['Var']=np.array(categorical)\n",
    "    \n",
    "    df_categorical['type']='categorical'\n",
    "    for col in [c for c in df_desc.columns if c not in ['Var','type']]:\n",
    "        df_categorical[col]=np.nan\n",
    "    for col in categorical:\n",
    "        df_var = data[col].value_counts()\n",
    "        df_cat = pd.DataFrame()\n",
    "        df_cat['count']=df_var\n",
    "        df_cat['categories']=df_var.index\n",
    "        df_cat.reset_index(inplace=True)\n",
    "        df_cat.sort_values(by='count',ascending=False,inplace=True)\n",
    "        df_cat.set_index('categories',inplace=True)\n",
    "        index_list = df_cat.index.tolist()\n",
    "        for i,c in enumerate(['mean','min','1%','5%','10%','25%']):\n",
    "            try:\n",
    "                df_categorical.loc[df_categorical['Var']==col,c] = index_list[i]\n",
    "            except:\n",
    "                break\n",
    "        for i,c in enumerate(['50%','75%','90%','95%','99%','max']):\n",
    "            try:\n",
    "                df_categorical.loc[df_categorical['Var']==col,c] = index_list[-(i+1)]\n",
    "            except:\n",
    "                break\n",
    "        del df_var\n",
    "        del df_cat\n",
    "        del index_list\n",
    "    df_categorical = df_categorical[df_desc.columns]\n",
    "    edd = pd.concat([df_desc,df_categorical])\n",
    "    del df_desc\n",
    "    del df_categorical\n",
    "    edd['count'] = edd['Var'].apply(lambda x: data[data[x].notnull()].shape[0])\n",
    "    edd['nmiss'] = data.shape[0]-edd['count']\n",
    "    edd['missing_rate'] = np.array(edd['nmiss']).astype('float')/data.shape[0] * 100\n",
    "    edd['unique'] = edd['Var'].apply(lambda x: len(data[x].value_counts().index.tolist()))\n",
    "    orig_cols = ['mean','min','1%','5%','10%','25%','50%','75%','90%','95%','99%','max']\n",
    "    new_cols = ['mean_or_top1','min_or_top2','p1_or_top3','p5_or_top4','p10_or_top5','p25_or_top6',\n",
    "                'p50_or_bottom6','p75_or_bottom5','p90_or_bottom4','p95_or_bottom3','p99_or_bottom2','max_or_bottom1']\n",
    "    \n",
    "    convert_dict = {}\n",
    "    for i in range(len(orig_cols)):\n",
    "        convert_dict[orig_cols[i]]=new_cols[i]\n",
    "    edd.rename(columns=convert_dict,inplace=True)\n",
    "    edd = edd[['Var','type','count','nmiss','missing_rate','unique','std','skewness','kurtosis','mean-3sigma',\n",
    "               'mean-2sigma','mean_or_top1','min_or_top2','p1_or_top3','p5_or_top4','p10_or_top5','p25_or_top6',\n",
    "               'p50_or_bottom6','p75_or_bottom5','p90_or_bottom4','p95_or_bottom3','p99_or_bottom2','max_or_bottom1'\n",
    "              ,'mean+2sigma','mean+3sigma']]\n",
    "    return edd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd =edd(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "from statsmodels.stats.weightstats import ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_value_stat(col,target='Survived'):\n",
    "    if col==target:\n",
    "        return None\n",
    "    try:\n",
    "        if edd.loc[edd['Var']==col,'type'].values[0]=='categorical':\n",
    "            obs_freq = []\n",
    "            for cat in df[col].value_counts().index.tolist():\n",
    "                obs_class=[]\n",
    "                for i in df[target].value_counts().index.tolist():\n",
    "                    obs = df[(df[col]==str(cat)) & (df[target]==i)].shape[0]\n",
    "                    obs_class.append(obs)\n",
    "                obs_freq.append(obs_class)\n",
    "            obs_freq=np.array(obs_freq)\n",
    "            return chisquare(obs_freq,axis=0)[1][0]\n",
    "        else:\n",
    "            return ztest(np.array(df.loc[(df[col].notnull()) & (df[target]==1),col]),\n",
    "                        np.array(df.loc[(df[col].notnull()) & (df[target]==0),col]))[1]\n",
    "    except Exception as e:\n",
    "        print(e,col)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd['Anova/Chisquare pvalue'] = edd['Var'].apply(lambda x: p_value_stat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../Statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd.to_csv('edd_after_treatment.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_drop =list(edd.loc[edd['unique']<2,'Var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(cols_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inter_correlation_clusters(data,cutoff=.7):\n",
    "    correlations=data.corr()\n",
    "    graph={}\n",
    "    columns=data.columns\n",
    "    for i in range(len(columns)):\n",
    "        graph[i]=[]\n",
    "        for j in range(len(columns)):\n",
    "            if i!=j and np.abs(correlations.iloc[i,j])>cutoff:\n",
    "                graph[i].append(j)\n",
    "    \n",
    "    tree_set={}\n",
    "    component = 0\n",
    "    visited = [0 for i in range(len(columns))]\n",
    "    def dfs(i):\n",
    "        visited[i]=1\n",
    "        try:\n",
    "            tree_set[component].append(i)\n",
    "        except KeyError:\n",
    "            tree_set[component] = [i]\n",
    "            \n",
    "        for j in graph[i]:\n",
    "            if visited[j]==0:\n",
    "                dfs(j)\n",
    "                \n",
    "    tree_cluster={}\n",
    "    for key in list(tree_set.keys()):\n",
    "        tree_cluster[key] = [columns[i] for i in tree_set[key]]\n",
    "        \n",
    "    return tree_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def varclus(data):\n",
    "    columns = []\n",
    "    correlations=data.corr()\n",
    "    clusters= inter_correlation_clusters(data)\n",
    "    print(clusters)\n",
    "    \n",
    "    cols = list(data.columns)\n",
    "    \n",
    "    def distance(c1,c2):\n",
    "        return np.max([[np.abs(correlations.loc[i,j]) for i in clusters[c1]] for j in clusters[c2]])\n",
    "    \n",
    "    def next_closest(c):\n",
    "        minima=0\n",
    "        point=c\n",
    "        for c1 in [i for i in list(clusters.keys()) if i!=c]:\n",
    "            dist = distance(c,c1)\n",
    "            if dist>minima:\n",
    "                minima=dist\n",
    "                point=c1\n",
    "        return point\n",
    "    \n",
    "    def get_squared_ratio(col,own_cluster,next_cluster):\n",
    "        y = np.array(data[col])\n",
    "        x = np.array(data[own_cluster].drop(col,axis=1))\n",
    "        model=LinearRegression()\n",
    "        model.fit(x,y)\n",
    "        y_pred = list(model.predict(x))\n",
    "        del x\n",
    "        del model\n",
    "        r2_own = r2_score(y,y_pred)\n",
    "        del y_pred\n",
    "        x = np.array(data[next_cluster])\n",
    "        model=LinearRegression()\n",
    "        model.fit(x,y)\n",
    "        y_pred = list(model.predict(x))\n",
    "        del x\n",
    "        del model\n",
    "        r2_next = r2_score(y,y_pred)\n",
    "        del y\n",
    "        del y_pred\n",
    "        \n",
    "        return float(1-r2_own)/(1-r2_next)\n",
    "    \n",
    "    for c1 in list(clusters.keys()):\n",
    "        if len(clusters[c1])>1:\n",
    "            own_cluster = clusters[c1]\n",
    "            next_cluster = clusters[next_closest(c1)]\n",
    "            ration=np.inf\n",
    "            for col in clusters[c1]:\n",
    "                col_ratio = get_squared_ratio(col,own_cluster,next_cluster)\n",
    "                if col_ratio<ratio:\n",
    "                    ratio=col_ratio\n",
    "                    clust_col=col\n",
    "            columns.append(clust_col)\n",
    "        else:\n",
    "            columns.append(clusters[c1][0])\n",
    "            \n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "columns = varclus(df.drop(['Survived'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if True in np.isinf(np.array(df[col])):\n",
    "        print col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 23)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "import statsmodels\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variance_inflation(data):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['features'] = data.columns\n",
    "    vif['vif factor'] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "    vif.sort_values(by='vif factor',ascending=False,inplace=True)\n",
    "    vif.reset_index(inplace=True)\n",
    "    vif.drop(['index'],axis=1,inplace=True)\n",
    "    print(vif)\n",
    "    return tuple(vif.loc[0,:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vif_drop_cols=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vif_reduction(data,limit=2.5):\n",
    "    vif = variance_inflation(data)\n",
    "    if vif[1]<=limit:\n",
    "        return\n",
    "    else:\n",
    "        data.drop(vif[0],axis=1,inplace=True)\n",
    "        vif_drop_cols.append(vif[0])\n",
    "        print(vif[0]+' dropped')\n",
    "        del vif\n",
    "        vif_reduction(data,limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              features  vif factor\n",
      "0                  Age    4.876435\n",
      "1   Pclass_dum_1 class    4.671065\n",
      "2         Sex_dum_male    3.846066\n",
      "3   Pclass_dum_3 class    3.536203\n",
      "4                 Fare    2.957105\n",
      "5                SibSp    1.876113\n",
      "6                Parch    1.855157\n",
      "7          Title_dum_0    1.823725\n",
      "8         Ticket_dum_0    1.749816\n",
      "9          Cabin_dum_1    1.649530\n",
      "10        Ticket_dum_1    1.635919\n",
      "11         Title_dum_1    1.580751\n",
      "12         Cabin_dum_0    1.568212\n",
      "13      Embarked_dum_0    1.396590\n",
      "14        Ticket_dum_2    1.263407\n",
      "15      Embarked_dum_1    1.245544\n",
      "16         Title_dum_2    1.192343\n",
      "17         Cabin_dum_2    1.190940\n",
      "18        Ticket_dum_3    1.190451\n",
      "19         Title_dum_3    1.115498\n",
      "20        Ticket_dum_4    1.112128\n",
      "21         Cabin_dum_3    1.020477\n",
      "Age dropped\n",
      "              features  vif factor\n",
      "0   Pclass_dum_1 class    4.084489\n",
      "1   Pclass_dum_3 class    3.184053\n",
      "2         Sex_dum_male    3.037451\n",
      "3                 Fare    2.938777\n",
      "4                Parch    1.855058\n",
      "5          Title_dum_0    1.820682\n",
      "6                SibSp    1.800769\n",
      "7         Ticket_dum_0    1.745254\n",
      "8          Cabin_dum_1    1.649280\n",
      "9         Ticket_dum_1    1.605712\n",
      "10         Cabin_dum_0    1.567775\n",
      "11         Title_dum_1    1.452271\n",
      "12      Embarked_dum_0    1.396509\n",
      "13        Ticket_dum_2    1.259302\n",
      "14      Embarked_dum_1    1.231518\n",
      "15         Cabin_dum_2    1.190748\n",
      "16        Ticket_dum_3    1.181270\n",
      "17         Title_dum_2    1.176827\n",
      "18         Title_dum_3    1.114536\n",
      "19        Ticket_dum_4    1.109216\n",
      "20         Cabin_dum_3    1.020364\n",
      "Pclass_dum_1 class dropped\n",
      "              features  vif factor\n",
      "0   Pclass_dum_3 class    2.906807\n",
      "1         Sex_dum_male    2.846819\n",
      "2                 Fare    2.308043\n",
      "3                Parch    1.839014\n",
      "4          Title_dum_0    1.815063\n",
      "5                SibSp    1.800707\n",
      "6         Ticket_dum_0    1.711751\n",
      "7         Ticket_dum_1    1.578956\n",
      "8          Title_dum_1    1.433811\n",
      "9          Cabin_dum_0    1.383994\n",
      "10         Cabin_dum_1    1.376040\n",
      "11      Embarked_dum_0    1.362829\n",
      "12        Ticket_dum_2    1.254475\n",
      "13      Embarked_dum_1    1.230871\n",
      "14        Ticket_dum_3    1.178073\n",
      "15         Title_dum_2    1.169240\n",
      "16         Cabin_dum_2    1.158832\n",
      "17         Title_dum_3    1.110112\n",
      "18        Ticket_dum_4    1.105014\n",
      "19         Cabin_dum_3    1.005936\n",
      "Pclass_dum_3 class dropped\n",
      "          features  vif factor\n",
      "0             Fare    2.151973\n",
      "1            Parch    1.798952\n",
      "2            SibSp    1.788088\n",
      "3     Ticket_dum_0    1.683398\n",
      "4     Ticket_dum_1    1.562006\n",
      "5      Title_dum_0    1.558225\n",
      "6     Sex_dum_male    1.554905\n",
      "7      Title_dum_1    1.394339\n",
      "8      Cabin_dum_1    1.358761\n",
      "9   Embarked_dum_0    1.356138\n",
      "10     Cabin_dum_0    1.353852\n",
      "11    Ticket_dum_2    1.252236\n",
      "12    Ticket_dum_3    1.173079\n",
      "13  Embarked_dum_1    1.167487\n",
      "14     Cabin_dum_2    1.142107\n",
      "15     Title_dum_3    1.109672\n",
      "16    Ticket_dum_4    1.104968\n",
      "17     Title_dum_2    1.104382\n",
      "18     Cabin_dum_3    1.004030\n"
     ]
    }
   ],
   "source": [
    "vif_reduction(df.drop(['Survived'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vif_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../Statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd = pd.read_csv('edd_v03.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd.loc[edd['Var'].isin(vif_drop_cols),'Status']='drop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd['Reason']=''\n",
    "edd.loc[edd['Var'].isin(vif_drop_cols),'Reason']='VIF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd.to_csv('edd_v04.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(vif_drop_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../output_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('train_v04.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackWard Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.discrete.discrete_model as sm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.420185\n",
      "         Iterations: 35\n",
      "Cabin_dum_3-0.998449263888\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420427\n",
      "         Iterations 7\n",
      "Embarked_dum_1-0.967796654326\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420428\n",
      "         Iterations 7\n",
      "Ticket_dum_1-0.693436882623\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420538\n",
      "         Iterations 7\n",
      "Ticket_dum_3-0.646769403207\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420684\n",
      "         Iterations 7\n",
      "Title_dum_3-0.501292330786\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.421042\n",
      "         Iterations 6\n",
      "Ticket_dum_4-0.370179391733\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.421565\n",
      "         Iterations 6\n",
      "Cabin_dum_2-0.304046812961\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.422300\n",
      "         Iterations 6\n",
      "Title_dum_2-0.243284307824\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.423314\n",
      "         Iterations 6\n",
      "Ticket_dum_2-0.234286495475\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.424289\n",
      "         Iterations 6\n",
      "Ticket_dum_0-0.195796432258\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.425513\n",
      "         Iterations 6\n",
      "Cabin_dum_0-0.0421414371619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "flag=0\n",
    "cols_dropped=['Survived']\n",
    "while flag==0:\n",
    "    model = sm.Logit(endog=np.array(df['Survived']),exog=np.array(df.drop(cols_dropped,axis=1)))\n",
    "    results = model.fit()\n",
    "    pvalues=list(results.pvalues)\n",
    "    drop_index = pvalues.index(max(pvalues))\n",
    "    col_drop = df.drop(cols_dropped,axis=1).columns[drop_index]\n",
    "    print(col_drop+'-'+str(pvalues[drop_index]))\n",
    "    if pvalues[drop_index]>.05:\n",
    "        cols_dropped.append(col_drop)\n",
    "    else:\n",
    "        flag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_dropped.remove('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 20)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(cols_dropped,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'SibSp', u'Parch', u'Fare', u'Survived', u'Sex_dum_male',\n",
       "       u'Cabin_dum_0', u'Cabin_dum_1', u'Embarked_dum_0', u'Title_dum_0',\n",
       "       u'Title_dum_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../output_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('train_v05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../pickles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(vif_drop_cols,open('vif_drop_cols.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(cols_dropped,open('backward_drop_cols.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "675    0\n",
       "467    0\n",
       "598    0\n",
       "733    0\n",
       "414    0\n",
       "272    1\n",
       "303    0\n",
       "180    0\n",
       "634    0\n",
       "264    0\n",
       "807    0\n",
       "278    0\n",
       "816    0\n",
       "379    0\n",
       "873    0\n",
       "327    0\n",
       "844    0\n",
       "819    0\n",
       "203    0\n",
       "372    0\n",
       "655    0\n",
       "144    0\n",
       "412    0\n",
       "826    0\n",
       "130    0\n",
       "805    1\n",
       "785    0\n",
       "885    0\n",
       "132    0\n",
       "722    0\n",
       "      ..\n",
       "270    1\n",
       "374    0\n",
       "326    1\n",
       "196    1\n",
       "306    1\n",
       "709    1\n",
       "499    0\n",
       "298    0\n",
       "610    1\n",
       "269    1\n",
       "333    0\n",
       "857    1\n",
       "319    1\n",
       "690    1\n",
       "780    1\n",
       "731    1\n",
       "378    0\n",
       "701    1\n",
       "381    1\n",
       "717    1\n",
       "558    0\n",
       "119    0\n",
       "743    1\n",
       "89     1\n",
       "28     0\n",
       "342    1\n",
       "439    0\n",
       "259    1\n",
       "738    1\n",
       "680    1\n",
       "Name: Survived, Length: 712, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../Statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd = pd.read_csv('edd_v04.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd.loc[edd['Var'].isin(cols_dropped),'Status']='drop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd.loc[edd['Var'].isin(cols_dropped),'Reason']='Backward Selection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edd.to_csv('edd_v05.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../pickles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numericals_final = list(set(set(df.columns) & set(numerical)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numericals_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fare', 'SibSp', 'Parch']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericals_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies_final = [col for col in df.columns if 'dum' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dummies_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(numericals_final,open('numerical_final.pickle','wb'))\n",
    "pickle.dump(dummies_final,open('dummies_final.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.fit(np.array(df.drop(['Survived'],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(scale,open('scale.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = scale.transform(df.drop(['Survived'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 10)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=9, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variance_cumulative = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(61):\n",
    "    if variance_cumulative[i]>=.9:\n",
    "        n_components=i+1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=7, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(pca,open('pca.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca_weights = pd.DataFrame(pca.components_,columns=df.drop(['Survived'],axis=1).columns,index=['pc'+str(i)\n",
    "                                                                                                  for i in range(1,n_components+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca_magnitude_weights = pd.DataFrame(map(np.square,pca.components_),columns=df.drop(['Survived'],axis=1).columns,index=['pc'+str(i)\n",
    "                                                                                                  for i in range(1,n_components+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_dum_male</th>\n",
       "      <th>Cabin_dum_0</th>\n",
       "      <th>Cabin_dum_1</th>\n",
       "      <th>Embarked_dum_0</th>\n",
       "      <th>Title_dum_0</th>\n",
       "      <th>Title_dum_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pc1</th>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.435670</td>\n",
       "      <td>0.351451</td>\n",
       "      <td>-0.461055</td>\n",
       "      <td>0.205323</td>\n",
       "      <td>0.163297</td>\n",
       "      <td>0.099388</td>\n",
       "      <td>0.381673</td>\n",
       "      <td>0.355641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc2</th>\n",
       "      <td>-0.334634</td>\n",
       "      <td>-0.226143</td>\n",
       "      <td>0.427547</td>\n",
       "      <td>0.076164</td>\n",
       "      <td>0.446825</td>\n",
       "      <td>0.502386</td>\n",
       "      <td>0.387484</td>\n",
       "      <td>-0.170992</td>\n",
       "      <td>-0.129833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc3</th>\n",
       "      <td>0.380274</td>\n",
       "      <td>0.351322</td>\n",
       "      <td>0.180598</td>\n",
       "      <td>0.502213</td>\n",
       "      <td>0.188102</td>\n",
       "      <td>-0.028858</td>\n",
       "      <td>-0.123751</td>\n",
       "      <td>-0.584203</td>\n",
       "      <td>0.233043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc4</th>\n",
       "      <td>-0.306225</td>\n",
       "      <td>-0.050381</td>\n",
       "      <td>-0.203745</td>\n",
       "      <td>-0.240879</td>\n",
       "      <td>-0.158230</td>\n",
       "      <td>-0.139371</td>\n",
       "      <td>0.410489</td>\n",
       "      <td>-0.359597</td>\n",
       "      <td>0.679618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc5</th>\n",
       "      <td>0.224437</td>\n",
       "      <td>0.116116</td>\n",
       "      <td>0.258822</td>\n",
       "      <td>0.169093</td>\n",
       "      <td>-0.386473</td>\n",
       "      <td>-0.304810</td>\n",
       "      <td>0.709698</td>\n",
       "      <td>0.061336</td>\n",
       "      <td>-0.301430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc6</th>\n",
       "      <td>0.040679</td>\n",
       "      <td>0.128619</td>\n",
       "      <td>-0.027753</td>\n",
       "      <td>0.076327</td>\n",
       "      <td>-0.660474</td>\n",
       "      <td>0.727672</td>\n",
       "      <td>-0.062649</td>\n",
       "      <td>-0.054001</td>\n",
       "      <td>0.051316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc7</th>\n",
       "      <td>-0.573220</td>\n",
       "      <td>0.406784</td>\n",
       "      <td>0.497357</td>\n",
       "      <td>-0.139511</td>\n",
       "      <td>-0.229868</td>\n",
       "      <td>-0.242796</td>\n",
       "      <td>-0.303164</td>\n",
       "      <td>-0.141829</td>\n",
       "      <td>-0.123713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SibSp     Parch      Fare  Sex_dum_male  Cabin_dum_0  Cabin_dum_1  \\\n",
       "pc1  0.351064  0.435670  0.351451     -0.461055     0.205323     0.163297   \n",
       "pc2 -0.334634 -0.226143  0.427547      0.076164     0.446825     0.502386   \n",
       "pc3  0.380274  0.351322  0.180598      0.502213     0.188102    -0.028858   \n",
       "pc4 -0.306225 -0.050381 -0.203745     -0.240879    -0.158230    -0.139371   \n",
       "pc5  0.224437  0.116116  0.258822      0.169093    -0.386473    -0.304810   \n",
       "pc6  0.040679  0.128619 -0.027753      0.076327    -0.660474     0.727672   \n",
       "pc7 -0.573220  0.406784  0.497357     -0.139511    -0.229868    -0.242796   \n",
       "\n",
       "     Embarked_dum_0  Title_dum_0  Title_dum_1  \n",
       "pc1        0.099388     0.381673     0.355641  \n",
       "pc2        0.387484    -0.170992    -0.129833  \n",
       "pc3       -0.123751    -0.584203     0.233043  \n",
       "pc4        0.410489    -0.359597     0.679618  \n",
       "pc5        0.709698     0.061336    -0.301430  \n",
       "pc6       -0.062649    -0.054001     0.051316  \n",
       "pc7       -0.303164    -0.141829    -0.123713  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca_weights.to_csv('pca_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca_magnitude_weights.to_csv('pca_magnitude_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(pca.transform(x),columns=['pc'+str(i) for i in range(1,n_components+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca['Survived']=df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../output_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca['Survived'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca.to_csv('train_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
